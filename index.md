#### Abstract

_We present Okutama-Action, a new video dataset for aerial view concurrent human action detection. It consists of 43 minute-long fully-annotated sequences with 12 action classes. Okutama-Action features many challenges missing in current datasets, including dynamic transition of actions, significant changes in scale and aspect ratio, abrupt camera movement, as well as multi-labeled actors. As a result, our dataset is more challenging than existing ones, and will help push the field forward to enable real-world applications._

#### Publications

<img style="float: left; margin-top:5px; width:30%" src="images/teaser.png" alt="arXiv">

Okutama-Action: An Aerial View Video Dataset for Concurrent Human Action Detection
                    <br>
                    <a href="http://barekatain.me/" target="_blank">M. Barekatain</a>,
                    <a href="https://miquelmarti.github.io" target="_blank">M. Mart√≠</a>,
                    <a href="https://www.linkedin.com/in/hsueh-fu-shih-621616b5/" target="_blank">H. Shih</a>,
                    <a href="https://www.linkedin.com/in/samuel-murray-6012545a" target="_blank">S. Murray</a>,
                    <a href="http://knakayama.com/" target="_blank">K. Nakayama</a>,
                    <a href="http://ymatsuo.com/" target="_blank">Y. Matsuo</a>, and
                    <a href="http://research.nii.ac.jp/~prendinger/" target="_blank">H. Prendinger</a>
                    <br>
                                       <i>arXiv:1706.03038, 2017</i><br>
                    [<a href="https://arxiv.org/abs/1706.03038" target="_blank">PDF</a>]

#### Annotation examples

TODO

#### Download

TODO

#### About

TODO
