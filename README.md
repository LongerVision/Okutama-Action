#### Abstract

_We present Okutama-Action, a new video dataset for aerial view concurrent human action detection. It consists of 43 minute-long fully-annotated sequences with 12 action classes. Okutama-Action features many challenges missing in current datasets, including dynamic transition of actions, significant changes in scale and aspect ratio, abrupt camera movement, as well as multi-labeled actors. As a result, our dataset is more challenging than existing ones, and will help push the field forward to enable real-world applications._

#### Publications

[Okutama-Action: An Aerial View Video Dataset for Concurrent Human Action Detection](https://arxiv.org/abs/1706.03038)

#### Annotation examples

TODO

#### Download

Find the training set of Okutama-Action in the following [link](https://drive.google.com/drive/folders/0B6O3GZcCIFuDaUs4dG1HWWEyUWM?usp=sharing).

#### About

The creation of this dataset was supported by [Prendinger Lab](http://research.nii.ac.jp/~prendinger/) at the [National Institute of Informatics](http://www.nii.ac.jp/en/), Tokyo, Japan.
